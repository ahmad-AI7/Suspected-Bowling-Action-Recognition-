{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea6178GkNLrL",
        "outputId": "ef9e59ad-2314-4f7a-d516-7dc6049d0124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI81cfKftbFa"
      },
      "source": [
        "**DataSet Properties**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Define the directory containing the images\n",
        "directory = '/content/drive/MyDrive/Suspected labeled dataset/ILLegal'\n",
        "\n",
        "# Get the list of all files in the directory\n",
        "all_files = os.listdir(directory)\n",
        "total_files = len(all_files)\n",
        "\n",
        "# Function to display progress\n",
        "def display_progress(progress):\n",
        "    print(f'\\rProgress: [{progress * \"#\"}{(100-progress) * \"-\"}] {progress}%', end='')\n",
        "\n",
        "# Rename all files in the directory\n",
        "for i, filename in enumerate(all_files):\n",
        "    old_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(old_path):\n",
        "        new_filename = f'Illegal Action {i+1}.jpg'\n",
        "        new_path = os.path.join(directory, new_filename)\n",
        "        os.rename(old_path, new_path)\n",
        "        # Calculate and display progress\n",
        "        progress = int(((i+1) / total_files) * 100)\n",
        "        display_progress(progress)\n",
        "        time.sleep(0.1)  # Adding a slight delay for visibility of progress (can be removed)\n",
        "\n",
        "print(\"\\nRenaming completed.\")\n"
      ],
      "metadata": {
        "id": "D6GziZdMeiK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a091fc-d45e-4c53-ca4b-9d34529c27f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: [####################################################################################################] 100%\n",
            "Renaming completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FBpU3DPsWHS",
        "outputId": "1f1b9a24-4f6e-41a2-b670-02d718a7f873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total Folders: 4\n",
            "Total Files: 1826\n",
            "Image Files: 1826\n",
            "Non-Image Files: 0\n",
            "File: /content/drive/MyDrive/Suspected bowling action Dataset/Left Arm Legal/IMG_7231.jpg\n",
            "Properties: {'format': 'JPEG', 'mode': 'RGB', 'size': (3024, 4032)}\n",
            "File: /content/drive/MyDrive/Suspected bowling action Dataset/Left Arm Legal/IMG_7230.jpg\n",
            "Properties: {'format': 'JPEG', 'mode': 'RGB', 'size': (3024, 4032)}\n",
            "File: /content/drive/MyDrive/Suspected bowling action Dataset/Left Arm Legal/IMG_7234.jpg\n",
            "Properties: {'format': 'JPEG', 'mode': 'RGB', 'size': (3024, 4032)}\n",
            "File: /content/drive/MyDrive/Suspected bowling action Dataset/Left Arm Legal/IMG_7229.jpg\n",
            "Properties: {'format': 'JPEG', 'mode': 'RGB', 'size': (3024, 4032)}\n",
            "File: /content/drive/MyDrive/Suspected bowling action Dataset/Left Arm Legal/IMG_7227.jpg\n",
            "Properties: {'format': 'JPEG', 'mode': 'RGB', 'size': (3024, 4032)}\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the dataset path\n",
        "dataset_path = '/content/drive/MyDrive/Suspected bowling action Dataset'\n",
        "\n",
        "def get_image_properties(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return {\n",
        "            'format': img.format,\n",
        "            'mode': img.mode,\n",
        "            'size': img.size\n",
        "        }\n",
        "\n",
        "def explore_dataset(path):\n",
        "    dataset_info = {\n",
        "        'total_folders': 0,\n",
        "        'total_files': 0,\n",
        "        'image_files': 0,\n",
        "        'non_image_files': 0,\n",
        "        'image_properties': []\n",
        "    }\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        dataset_info['total_folders'] += len(dirs)\n",
        "        dataset_info['total_files'] += len(files)\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                properties = get_image_properties(file_path)\n",
        "                dataset_info['image_files'] += 1\n",
        "                dataset_info['image_properties'].append({\n",
        "                    'file_path': file_path,\n",
        "                    'properties': properties\n",
        "                })\n",
        "            except Exception as e:\n",
        "                dataset_info['non_image_files'] += 1\n",
        "\n",
        "    return dataset_info\n",
        "\n",
        "# Explore the dataset\n",
        "dataset_info = explore_dataset(dataset_path)\n",
        "\n",
        "# Print the dataset info\n",
        "print(f\"Total Folders: {dataset_info['total_folders']}\")\n",
        "print(f\"Total Files: {dataset_info['total_files']}\")\n",
        "print(f\"Image Files: {dataset_info['image_files']}\")\n",
        "print(f\"Non-Image Files: {dataset_info['non_image_files']}\")\n",
        "\n",
        "# Display a few image properties\n",
        "for img_info in dataset_info['image_properties'][:5]:\n",
        "    print(f\"File: {img_info['file_path']}\")\n",
        "    print(f\"Properties: {img_info['properties']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xZE2y0BthQR"
      },
      "source": [
        "**Model Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-0XL7Mqtk9_",
        "outputId": "799a4ce3-7a21-46fb-b80a-89ebdb055cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#... (rest of the code)"
      ],
      "metadata": {
        "id": "F8esLZ1SCdJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import json\n",
        "\n",
        "# Define the paths\n",
        "dataset_path = '/content/drive/MyDrive/Suspected labeled dataset'\n",
        "save_path = '/content/drive/MyDrive/Model'  # Path to save model and metadata\n",
        "\n",
        "# ImageDataGenerator for data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # 20% validation data\n",
        ")\n",
        "\n",
        "# Load images from the directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),  # VGG16 expects 224x224 images\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Print the number of samples in the training and validation sets\n",
        "print(f\"Number of training samples: {train_generator.samples}\")\n",
        "print(f\"Number of validation samples: {validation_generator.samples}\")\n",
        "\n",
        "# Ensure the number of steps per epoch is greater than zero\n",
        "steps_per_epoch = max(1, train_generator.samples // train_generator.batch_size)\n",
        "validation_steps = max(1, validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Load the VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of VGG16\n",
        "for layer in base_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # Adjust the output layer according to the number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=RMSprop(learning_rate=1e-5),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(f'{save_path}/best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Save the model architecture and weights\n",
        "model.save(f'{save_path}/Suspected_BA_final_model.h5')\n",
        "\n",
        "# Save model metadata\n",
        "metadata = {\n",
        "    'input_shape': (224, 224, 3),\n",
        "    'num_classes': train_generator.num_classes,\n",
        "    'base_model': 'VGG16',\n",
        "    'trainable_layers': 15,\n",
        "    'optimizer': 'RMSprop',\n",
        "    'learning_rate': 1e-5,\n",
        "    'loss_function': 'categorical_crossentropy',\n",
        "    'epochs': 10,\n",
        "    'callbacks': ['ModelCheckpoint', 'EarlyStopping']\n",
        "}\n",
        "\n",
        "with open(f'{save_path}/Suspected_BA_model_metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "geu2eNQDg5VJ",
        "outputId": "91f2ddcd-b174-4b0a-9d1d-599689459d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1406 images belonging to 2 classes.\n",
            "Found 351 images belonging to 2 classes.\n",
            "Number of training samples: 1406\n",
            "Number of validation samples: 351\n",
            "Error in model summary: Undefined shapes are not supported.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=/content/drive/MyDrive/Model/best_model.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7ae142c8efa7>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# Define callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{save_path}/best_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0;34m\"The filepath provided must end in `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0;34m\"(Keras model format). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=/content/drive/MyDrive/Model/best_model.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "qaQr_FY3Jfdk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uo4PpJT8UOcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the model\n",
        "model_path = '/content/drive/MyDrive/Model/Suspected_BA_final_model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Load the model metadata\n",
        "metadata_path = '/content/drive/MyDrive/Model/Suspected_BA_model_metadata.json'\n",
        "with open(metadata_path, 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Define the class labels based on your training setup\n",
        "class_labels = ['Illegal', 'Legal']  # Adjust if necessary\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(image_path, target_size):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "    return img_array\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image(image_path):\n",
        "    img_array = preprocess_image(image_path, (224, 224))  # Adjust target size based on your model\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)\n",
        "    predicted_label = class_labels[predicted_class[0]]\n",
        "    return predicted_label\n",
        "\n",
        "# Test the model with a sample image\n",
        "test_image_path = '/content/drive/MyDrive/Testing data/Ill2.jpg'  # Replace with the path to your test image\n",
        "predicted_label = predict_image(test_image_path)\n",
        "print(f'The action in the given image is: {predicted_label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtrzuW1a4dv1",
        "outputId": "4a61f7d0-6637-464d-8935-3be09faa82b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79e6f4485510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 242ms/step\n",
            "The action in the given image is: Illegal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: google drive mount code\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsb6456OCXNG",
        "outputId": "42bf4979-1d88-481d-bf59-cb5142b74ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Model/Suspected_BA_final_model.h5')\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the converted model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "rC9UeIjV4dqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-nYe0vWt--R"
      },
      "outputs": [],
      "source": [
        "# prompt: give me the path of the saved file\n",
        "\n",
        "model_path = 'model.tflite'\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}